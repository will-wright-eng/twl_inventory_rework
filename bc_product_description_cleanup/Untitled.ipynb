{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from google.cloud import bigquery\n",
    "\n",
    "###\n",
    "import config_utility\n",
    "credential_path = config_utility.gbq_credential_path\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path\n",
    "\n",
    "today = str(dt.datetime.today()).split(' ')[0]\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "\n",
    "def list_files_in_directory(path):\n",
    "    '''docstring for list_files_in_directory'''\n",
    "    x = []\n",
    "    cwd = os.getcwd()\n",
    "    for root, dirs, files in os.walk('.'+path):\n",
    "        for file in files:\n",
    "            #print(root+'/'+file)\n",
    "            x.append(root+'/'+file)\n",
    "    return x\n",
    "\n",
    "def display_file_list(files):\n",
    "    '''docstring for display_file_list'''\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(len(df))\n",
    "            display(df.head())\n",
    "        except EmptyDataError as e:\n",
    "            print(e)\n",
    "    return\n",
    "\n",
    "def download_table_from_gbq(project_name, dataset_name, table_name):\n",
    "    '''docstring for download_table_from_gbq'''\n",
    "    # https://cloud.google.com/bigquery/docs/pandas-gbq-migration\n",
    "    client = bigquery.Client()\n",
    "    sql = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `{project}.{dataset}.{table}`\n",
    "        \"\"\"\n",
    "    query = sql.format(project=project_name, dataset=dataset_name, table=table_name)\n",
    "    # Run a Standard SQL query using the environment's default project\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    # Run a Standard SQL query with the project set explicitly\n",
    "    project_id = 'peronal-data-projects'\n",
    "    df = client.query(sql, project=project_id).to_dataframe()\n",
    "    return df\n",
    "\n",
    "def upload_table_to_gbq(df, dataset_name, table_name):\n",
    "    '''docstring for upload_table_to_gbq'''\n",
    "    #https://cloud.google.com/bigquery/docs/pandas-gbq-migration\n",
    "    client = bigquery.Client()\n",
    "    table_id = dataset_name+'.'+table_name\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    # Wait for the load job to complete.\n",
    "    print('job complete')\n",
    "    return job.result()\n",
    "\n",
    "# ###\n",
    "# # download table from google bigquery script_uploads dataset\n",
    "# project_name = 'peronal-data-projects'\n",
    "# dataset_name = 'script_uploads'\n",
    "# table_name = 'raw_twl_customer_table'\n",
    "# df = download_table_from_gbq(project_name, dataset_name, table_name)\n",
    "\n",
    "# ###\n",
    "# # upload dataframe to google bigquery script_uploads dataset\n",
    "# dataset_name = 'script_uploads'\n",
    "# table_name = 'raw_recurring_spend_tracking_sheet'\n",
    "# upload_table_to_gbq(ndf, dataset_name, table_name)\n",
    "\n",
    "###\n",
    "# create list of files in directory\n",
    "path = '/lightspeed'\n",
    "x = list_files_in_directory(path)\n",
    "# select for csvs\n",
    "files = [i for i in x if 'csv' in i]\n",
    "# [i for i in files if 'transaction' in i]\n",
    "# select for inventory table\n",
    "items = [i for i in files if 'item' in i][0]\n",
    "# dataframe from local file\n",
    "df = pd.read_csv(items)\n",
    "cols = [i.replace(' ','_').replace('.','').lower() for i in list(df)]\n",
    "df.columns = cols\n",
    "\n",
    "###\n",
    "# upload dataframe to google bigquery script_uploads dataset\n",
    "dataset_name = 'script_uploads'\n",
    "table_name = 'raw_twl_customer_table'\n",
    "# upload_table_to_gbq(df, dataset_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales = [i for i in files if 'transaction' in i]\n",
    "# display_file_list(sales)\n",
    "\n",
    "filename = './lightspeed/csvs/sales/2020-07-12_reports_sales_listings_transaction_line(3).csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df0 = pd.read_csv(items)\n",
    "df1 = df0.drop_duplicates(subset = 'Item', keep = 'first', inplace = False)\n",
    "\n",
    "ndf = df.merge(df1,left_on='Description',right_on='Item',how='left')\n",
    "cols = [i.replace(' ','_').replace('.','').lower() for i in list(ndf)]\n",
    "ndf.columns = cols\n",
    "\n",
    "###\n",
    "# upload dataframe to google bigquery script_uploads dataset\n",
    "dataset_name = 'script_uploads'\n",
    "table_name = 'base_twl_sales_with_item_info'\n",
    "# upload_table_to_gbq(ndf, dataset_name, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_order_internal_note\n",
      "system_id\n",
      "upc\n",
      "ean\n",
      "season\n",
      "department\n",
      "msrp\n",
      "default_cost\n",
      "subcategory_1\n",
      "subcategory_2\n",
      "subcategory_3\n",
      "subcategory_4\n",
      "subcategory_5\n",
      "subcategory_6\n",
      "subcategory_7\n",
      "subcategory_8\n",
      "subcategory_9\n"
     ]
    }
   ],
   "source": [
    "dfs = [pd.DataFrame(ndf.dtypes).T\n",
    "       , pd.DataFrame(ndf.count()).T]\n",
    "\n",
    "temp = pd.concat(dfs).T\n",
    "temp.columns = ['type','counts']\n",
    "l = list(temp.loc[temp['type']=='float64'].index)\n",
    "for i in l:\n",
    "    print(i)\n",
    "    for j in ndf[i]:\n",
    "        #print(j)\n",
    "        try:\n",
    "            if '<' in j:\n",
    "                print(i,'---',j)\n",
    "        except TypeError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'base_twl_sales_with_item_info'\n",
    "ndf.to_csv(today+'_'+table_name+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndf.loc[ndf['category']=='Disc']#.loc[ndf['qty']]\n",
    "# # remove second qty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting flat txt file to csv\n",
    "\n",
    "test = pd.read_fwf([i for i in x if 'txt' in i][0])\n",
    "# pd.read_csv([i for i in x if 'txt' in i][0], sep=\"  \", header=None)\n",
    "\n",
    "cols = list(test)[0].split('\\t')\n",
    "data = list(test[list(test)[0]])\n",
    "data_list = []\n",
    "for row in data:\n",
    "    data_list.append(row.split('\\t'))\n",
    "    \n",
    "test2 = pd.DataFrame(data_list)\n",
    "# display(test2)\n",
    "test2.columns = cols\n",
    "filename = [i for i in x if 'txt' in i][0].replace('txt','csv')\n",
    "test2.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i in x if 'txt' in i][0].replace('txt','csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
